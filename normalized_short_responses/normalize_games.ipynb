{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from thefuzz import process\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils import transtable\n",
    "import utils as plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../raw_data/census.csv')\n",
    "gd = data.replace('nan', np.nan)\n",
    "# gd = data[['timestamp','have_ordered', 'have_playdate', 'satisfied_with_season','season_feedback','spoiler_free','satisfied_with_games','most_exciting_game','season_game_feedback','purchase_season_2','pay_for_12_games','pay_for_24_games','have_purchased_game','quick_hit_price','short_price','standard_price','long_price','highest_price','known_developer','game_tags','session_10min','session_30min','session_60min','session_hour_plus','most_excited_game']]\n",
    "gd = gd.astype({'season_feedback':str})\n",
    "for col in ['have_ordered', 'have_playdate']:\n",
    "    gd[col] = gd[col] == 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_games = '''\n",
    "    whitewater wipeout \n",
    "    casual birder\n",
    "    crankins time travel adventure \n",
    "    boogie loops\n",
    "    lost your marbles\n",
    "    pick pack pup\n",
    "    flipper lifter\n",
    "    echoic memory\n",
    "    omaze\n",
    "    demon quest 85\n",
    "    zipper \n",
    "    hyper meteor\n",
    "    questy chess\n",
    "    executive golf dx \n",
    "    saturday edition\n",
    "    star sled \n",
    "    inventory hero\n",
    "    spellcorked \n",
    "    snak \n",
    "    sasquatchers \n",
    "    forrest byrnes up in smoke\n",
    "    battleship godios\n",
    "    b360  \n",
    "    ratcheteer\n",
    "'''\n",
    "extra_vocab = '''\n",
    "    surfin surfing surf bird birding cranking crank crankin loop golfing business office starsled spell corked sasquatcher 360 snake\n",
    "'''\n",
    "s1_games_list = [g.strip() for g in s1_games.split('\\n')]\n",
    "s1_games_list = set(s1_games_list)\n",
    "s1_games_list.remove('')\n",
    "game_vocab = (s1_games + extra_vocab).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'game':list(s1_games_list), 'week':[7, 6, 2, 9, 12, 1, 8, 5, 3, 11, 4, 3, 6, 1, 10, 12, 9, 5, 2, 7, 8, 10, 11, 4]}).to_csv('s1_games_week.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_game(val, vocab=None):\n",
    "    if val is None or pd.isna(val): return None\n",
    "    res = []\n",
    "    val = val.lower().strip().translate(transtable)\n",
    "    words = val.split()\n",
    "    for word in words:\n",
    "        if vocab and word in vocab:\n",
    "            res.append(word)\n",
    "        elif not vocab:\n",
    "            res.append(word)\n",
    "    \n",
    "    return ' '.join(res)\n",
    "\n",
    "def export_list_to_fix(data, col, vocab, games):\n",
    "    favs = data[data[col].notna()].copy()\n",
    "    favs['normalized'] = favs[col].apply(lambda x: normalize_game(x, vocab))\n",
    "    favs['inspect'] = favs.normalized.apply(lambda x: x not in games)\n",
    "    favs[[col, 'normalized', 'inspect']].to_excel(col+'.xlsx')\n",
    "\n",
    "    return favs\n",
    "\n",
    "def import_fixed_list(filename, source_df):\n",
    "    source_df = source_df.copy()\n",
    "    fixed_favs = pd.read_csv(filename, index_col=0).normalized\n",
    "    source_df['fixed'] = fixed_favs\n",
    "    source_df = source_df[['timestamp', 'fixed','have_playdate','have_ordered']]\n",
    "    # source_df = source_df.fillna('')\n",
    "    return source_df\n",
    "\n",
    "def get_freq_count(s, multiple_choice=True):\n",
    "    s = s[s.notna()]\n",
    "    def make_item_list():\n",
    "        return [x.strip() for x in ' | '.join(s).split('|') if x.strip() != '' ]\n",
    "\n",
    "    from collections import Counter\n",
    "    fav_items = s.values\n",
    "    if multiple_choice:\n",
    "        fav_items = make_item_list()\n",
    "    fav_items = Counter(fav_items).most_common()\n",
    "    return fav_items\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Normalized List of S1 Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = export_list_to_fix(gd, 'most_exciting_game', game_vocab, s1_games_list)\n",
    "fav_s1_games = import_fixed_list('fixed_s1_games.csv', temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify common non S1 Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_game_comments = gd[gd.most_excited_game.notna()].most_excited_game\n",
    "\n",
    "v = CountVectorizer(stop_words='english', strip_accents='ascii', ngram_range=(1,4))\n",
    "bow = v.fit_transform(upcoming_game_comments)\n",
    "sum_words = bow.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in v.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "top_words = words_freq[101:]\n",
    "# vocab = list(zip(*top_words))[0]\n",
    "upcoming_games = {\n",
    "    'mars after midnight':'lucas pope',\n",
    "    'daily driver':'gingerbeardman',\n",
    "    'wastebraver tiny survival tale':'',\n",
    "    'atlantic 41':'submarine',\n",
    "    'playmaker':'',\n",
    "    'grand tour legends':'',\n",
    "    'p-racing':'p racing p-racer',\n",
    "    'voyage':'',\n",
    "    'giles goddard snowboarding':'chuhai labs',\n",
    "    'pullfrog':'amano pull frog',\n",
    "    'moonward':'',\n",
    "    'botanist':'',\n",
    "    'silver ball tactics':'silverball',\n",
    "    'rocket bytes':'possibly axolotl possiblyaxolotl',\n",
    "    'legend etad':'etud',\n",
    "    'poolsuite fm':'',\n",
    "    'kicooya':'',\n",
    "    'skwish':'',\n",
    "    'crank turismo':'',\n",
    "    'faraway fairway':'',\n",
    "    'tapeworm':'',\n",
    "    'bloom':'',\n",
    "    'mobware minigames':'wario ware',\n",
    "    'space kitsune':'starfox chuhai labs vector 3d'\n",
    "\n",
    "}\n",
    "upcoming_vocab = \" \".join(upcoming_games.keys()) + \" \" + \" \".join(upcoming_games.values())\n",
    "upcoming_vocab = upcoming_vocab.split()\n",
    "print(list(upcoming_games.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick closest game based on fuzzy search for each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [' '.join((k,v)).strip() for k,v in upcoming_games.items()]\n",
    "values = upcoming_games.keys()\n",
    "option_map = dict(zip(keys, values))\n",
    "\n",
    "def pick_closest(val, choices):\n",
    "    val = normalize_game(val)\n",
    "    if val:\n",
    "        closest = process.extractOne(val, choices)\n",
    "        if closest[1] >= 60:\n",
    "            return option_map[closest[0]]\n",
    "        else:\n",
    "            return 'other'\n",
    "    else:\n",
    "        return None\n",
    "       \n",
    "comments = gd[gd.most_excited_game.notna()].most_excited_game\n",
    "gd['normalized_upcoming_game'] = comments.apply(lambda x: pick_closest(x, keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize other multiple choice columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = gd[['timestamp','have_playdate','have_ordered','most_excited_game','normalized_upcoming_game']].dropna()\n",
    "# temp.to_excel('upcoming_games.xlsx')\n",
    "upcoming_games = import_fixed_list('fixed_upcoming_games.csv', gd)\n",
    "freqs = get_freq_count(upcoming_games.fixed, multiple_choice=False)\n",
    "top_cats = list(zip(*freqs))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exciting_s1 = plot.explode_multiple_choice(fav_s1_games, 'fixed')\n",
    "exciting_non_s1 = upcoming_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exciting_s1.to_csv('exciting_s1.csv',index=False)\n",
    "exciting_non_s1.to_csv('exciting_non_s1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_indies = pd.read_csv('other_indie_consoles_fixed.csv', usecols=range(3))\n",
    "def update_col_with_fixed(data, col, other_list = [], standard_vals=[]):\n",
    "    data.loc[data.fixed.notna(), col] = data.fixed.apply(lambda x: x + '*' if type(x) is str and x not in standard_vals else x)\n",
    "    data = data[data[col] != 'None*']\n",
    "    data.loc[data[col].isin(other_list), col] = 'Other'\n",
    "    return data\n",
    "other_indies = update_col_with_fixed(other_indies, 'other_indie_consoles', other_list=('Modded Gameboy', 'Pocket Sprite', 'Analogue Super Nt'), standard_vals=[\n",
    "    'Arduboy', 'Anbernic systems (RG552 ect)', 'Retroid Pocket', 'Analogue Pocket'\n",
    "])\n",
    "other_indies[['pdidx','other_indie_consoles']].to_csv('other_indie_consoles_cleaned.csv')\n",
    "other_indies.other_indie_consoles.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_col(df, col, standard_threshold=15):\n",
    "    exploded = plot.explode_multiple_choice(gd, col, ',')\n",
    "    standard_vals = exploded[col].value_counts().index[:standard_threshold].values\n",
    "    exploded['inspect'] = ~exploded[col].isin(standard_vals)\n",
    "    exploded = exploded[[col, 'inspect']]\n",
    "    exploded.to_csv(f'{col}_exploded.csv', index_label='pdidx')\n",
    "    return standard_vals\n",
    "\n",
    "def read_fixed_and_clean(col, other_list=[], standard_vals=[], ncols=3):\n",
    "    content = pd.read_csv(f'{col}_fixed.csv', usecols=range(ncols))\n",
    "    content = update_col_with_fixed(content, col, other_list, standard_vals)\n",
    "    content[['pdidx', col]].to_csv(f'{col}_cleaned.csv')\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_col(gd, 'playdate_content')\n",
    "read_fixed_and_clean('playdate_content', standard_vals=[\n",
    "    'Reddit', 'Twitter', 'Discord', 'Itch.io', 'Youtube', 'Official Playdate Forum', 'Playdate wiki', 'Twitch'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_values = explode_col(gd, 'dev_tools', standard_threshold=14)\n",
    "read_fixed_and_clean('dev_tools', standard_vals=standard_values, ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_values = explode_col(gd, 'dev_playdate_tools', standard_threshold=7)\n",
    "standard_values[-1] = 'Roomy-Playdate'\n",
    "read_fixed_and_clean('dev_playdate_tools', standard_vals=standard_values, ncols=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be1f11b77e582ef8bdffb301d9f77b0b26bcdcef6e8882b5b10ec1d29a538eae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
